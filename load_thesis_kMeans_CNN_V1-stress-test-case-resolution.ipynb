{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197005f3-bcf1-4be1-854a-881aaabcdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c56fb5-af25-4148-a533-2a5fb02dfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrustaceanIdentifierSystem:\n",
    "    def __init__(self, img_size=(224, 224), num_classes=5):\n",
    "        self.img_size = img_size\n",
    "        self.class_names = ['blue_swimming_crab','mud_crab','tiger_prawn','whiteleg_shrimp','river_crab']\n",
    "\n",
    "    def extract_color_features(self, image):\n",
    "        \"\"\"Extract color-based features from image\"\"\"\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            image_rgb = image\n",
    "        resized = cv2.resize(image_rgb, (64, 64))\n",
    "        hist_r = cv2.calcHist([resized], [0], None, [32], [0, 256])\n",
    "        hist_g = cv2.calcHist([resized], [1], None, [32], [0, 256])\n",
    "        hist_b = cv2.calcHist([resized], [2], None, [32], [0, 256])\n",
    "\n",
    "        # Calculate mean, standard, std, and skewness of color channels.\n",
    "        mean_colors = np.mean(resized.reshape(-1, 3), axis=0)\n",
    "        std_colors = np.std(resized.reshape(-1, 3), axis=0)\n",
    "        skew_colors = np.array([\n",
    "            np.mean(((resized[:, :, i] - mean_colors[i]) / std_colors[i])**3)\n",
    "            for i in range(3)\n",
    "        ])\n",
    "        features = np.concatenate([\n",
    "            hist_r.flatten(), hist_g.flatten(), hist_b.flatten(),\n",
    "            mean_colors, std_colors, skew_colors\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def extract_shape_features(self, image):\n",
    "        \"\"\"Extract shape-based features from image\"\"\"\n",
    "        # Convert to grayscale for shape analysis\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        # Resize for consistent feature extraction\n",
    "        gray_resized = cv2.resize(gray, (128, 128))\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray_resized, (5, 5), 0)\n",
    "        \n",
    "        # Threshold to create binary image\n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        shape_features = []\n",
    "        \n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            \n",
    "            # Basic shape measurements\n",
    "            area = cv2.contourArea(largest_contour)\n",
    "            perimeter = cv2.arcLength(largest_contour, True)\n",
    "            \n",
    "            # Aspect ratio and extent\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            aspect_ratio = float(w) / h if h != 0 else 0\n",
    "            rect_area = w * h\n",
    "            extent = float(area) / rect_area if rect_area != 0 else 0\n",
    "            \n",
    "            # Solidity (convex hull ratio)\n",
    "            hull = cv2.convexHull(largest_contour)\n",
    "            hull_area = cv2.contourArea(hull)\n",
    "            solidity = float(area) / hull_area if hull_area != 0 else 0\n",
    "            \n",
    "            # Circularity\n",
    "            circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter != 0 else 0\n",
    "            \n",
    "            # Moments for shape description\n",
    "            moments = cv2.moments(largest_contour)\n",
    "            if moments['m00'] != 0:\n",
    "                # Centroid\n",
    "                cx = int(moments['m10'] / moments['m00'])\n",
    "                cy = int(moments['m01'] / moments['m00'])\n",
    "                # Normalized central moments (Hu moments)\n",
    "                hu_moments = cv2.HuMoments(moments).flatten()\n",
    "                # Take log to make them more manageable\n",
    "                hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "            else:\n",
    "                hu_moments = np.zeros(7)\n",
    "            \n",
    "            # Equivalent diameter\n",
    "            equiv_diameter = np.sqrt(4 * area / np.pi) if area > 0 else 0\n",
    "            \n",
    "            # Compactness\n",
    "            compactness = (perimeter ** 2) / (4 * np.pi * area) if area > 0 else 0\n",
    "            \n",
    "            # Roundness\n",
    "            roundness = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
    "            \n",
    "            # Eccentricity (using fitted ellipse)\n",
    "            if len(largest_contour) >= 5:\n",
    "                ellipse = cv2.fitEllipse(largest_contour)\n",
    "                major_axis = max(ellipse[1])\n",
    "                minor_axis = min(ellipse[1])\n",
    "                eccentricity = np.sqrt(1 - (minor_axis / major_axis) ** 2) if major_axis > 0 else 0\n",
    "            else:\n",
    "                eccentricity = 0\n",
    "            \n",
    "            # Combine all shape features\n",
    "            shape_features = [\n",
    "                area / 10000,  # Normalized area\n",
    "                perimeter / 1000,  # Normalized perimeter\n",
    "                aspect_ratio,\n",
    "                extent,\n",
    "                solidity,\n",
    "                circularity,\n",
    "                equiv_diameter / 100,  # Normalized equivalent diameter\n",
    "                compactness,\n",
    "                roundness,\n",
    "                eccentricity,\n",
    "                *hu_moments  # 7 Hu moments\n",
    "            ]\n",
    "            \n",
    "        else:\n",
    "            # If no contours found, return zero features\n",
    "            shape_features = [0] * 17  # 10 basic features + 7 Hu moments\n",
    "        \n",
    "        return np.array(shape_features)\n",
    "\n",
    "    def extract_texture_features(self, image):\n",
    "        \"\"\"Extract texture-based features using Local Binary Pattern (LBP)\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        gray_resized = cv2.resize(gray, (64, 64))\n",
    "        \n",
    "        # Simple LBP implementation\n",
    "        def local_binary_pattern(img, radius=1, neighbors=8):\n",
    "            h, w = img.shape\n",
    "            lbp = np.zeros((h, w), dtype=np.uint8)\n",
    "            \n",
    "            for i in range(radius, h - radius):\n",
    "                for j in range(radius, w - radius):\n",
    "                    center = img[i, j]\n",
    "                    pattern = 0\n",
    "                    for k in range(neighbors):\n",
    "                        angle = 2 * np.pi * k / neighbors\n",
    "                        x = int(i + radius * np.cos(angle))\n",
    "                        y = int(j + radius * np.sin(angle))\n",
    "                        if 0 <= x < h and 0 <= y < w:\n",
    "                            if img[x, y] >= center:\n",
    "                                pattern |= (1 << k)\n",
    "                    lbp[i, j] = pattern\n",
    "            return lbp\n",
    "        \n",
    "        lbp = local_binary_pattern(gray_resized)\n",
    "        \n",
    "        # Calculate histogram of LBP\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=32, range=(0, 256))\n",
    "        hist = hist.astype(float)\n",
    "        hist /= (hist.sum() + 1e-10)  # Normalize\n",
    "        \n",
    "        # Additional texture features\n",
    "        # Contrast, homogeneity, energy\n",
    "        glcm_features = []\n",
    "        \n",
    "        # Simple contrast measure\n",
    "        contrast = np.var(gray_resized)\n",
    "        \n",
    "        # Homogeneity (inverse difference moment)\n",
    "        homogeneity = np.mean(gray_resized) / (np.std(gray_resized) + 1e-10)\n",
    "        \n",
    "        # Energy (uniformity)\n",
    "        energy = np.sum(hist ** 2)\n",
    "        \n",
    "        texture_features = np.concatenate([\n",
    "            hist,  # LBP histogram (32 features)\n",
    "            [contrast / 1000, homogeneity / 100, energy]  # Additional features (3 features)\n",
    "        ])\n",
    "        \n",
    "        return texture_features\n",
    "\n",
    "    def extract_combined_features(self, image):\n",
    "        \"\"\"Extract combined color, shape, and texture features\"\"\"\n",
    "        color_features = self.extract_color_features(image)\n",
    "        shape_features = self.extract_shape_features(image)\n",
    "        texture_features = self.extract_texture_features(image)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_features = np.concatenate([\n",
    "            color_features,\n",
    "            shape_features,\n",
    "            texture_features\n",
    "        ])\n",
    "        \n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7247537-5d0c-4e87-86f3-6d2f2a08ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 50 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Crustacean Identifier System class\n",
    "crustacean_system = CrustaceanIdentifierSystem()\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(r\"C:\\Users\\pc\\_djohn_files\\_model.keras\")\n",
    "\n",
    "# Load saved scaler and kmeans\n",
    "scaler = load(r\"C:\\Users\\pc\\_djohn_files\\_scaler.pkl\")\n",
    "kmeans_model = load(r\"C:\\Users\\pc\\_djohn_files\\_kmeans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668e605b-0d50-425d-a904-9d161750b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_input', 'cluster_input']\n"
     ]
    }
   ],
   "source": [
    "# Print inputs\n",
    "print([inp.name for inp in model.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8e562b-4076-4490-a596-3f58b5d33b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to unseen dataset\n",
    "test_dir = r\"D:\\_stress-test-case\\andoid-test-images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117db481-be56-4249-807b-18f5b5477129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Collect ground truth and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "# Define test resolutions\n",
    "resolutions = [(640, 480), (1280, 720), (1920, 1080)]\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for class_name in crustacean_system.class_names:\n",
    "    class_dir = os.path.join(test_dir, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Warning: {class_dir} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "\n",
    "        # Load original image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Could not read {img_path}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        for res in resolutions:\n",
    "            # Resize to test resolution\n",
    "            img_resized_test = cv2.resize(img, res)\n",
    "\n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Preprocess for CNN input\n",
    "            img_resized = cv2.resize(img_resized_test, crustacean_system.img_size)\n",
    "            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "            img_normalized = img_rgb / 255.0\n",
    "            img_batch = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "            # Extract cluster input\n",
    "            combined_features = crustacean_system.extract_combined_features(img_resized_test)\n",
    "            features_scaled = scaler.transform([combined_features])\n",
    "            cluster_label = kmeans_model.predict(features_scaled)[0]\n",
    "            cluster_input = tf.keras.utils.to_categorical(\n",
    "                [cluster_label], num_classes=kmeans_model.n_clusters\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            prediction = model.predict(\n",
    "                {\"image_input\": img_batch, \"cluster_input\": cluster_input}, verbose=0\n",
    "            )\n",
    "            predicted_class = np.argmax(prediction)\n",
    "\n",
    "            # End timing\n",
    "            end_time = time.time()\n",
    "            prediction_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "            results.append({\n",
    "                \"Image\": img_file,\n",
    "                \"Species\": class_name,\n",
    "                \"Resolution\": f\"{res[0]}x{res[1]}\",\n",
    "                \"Predicted\": crustacean_system.class_names[predicted_class],\n",
    "                \"Time (ms)\": round(prediction_time_ms, 2)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c82152c-54d6-4aef-9848-cbc8c81ea1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Image             Species Resolution           Predicted  Time (ms)\n",
      "0   bsc (1).jpg  blue_swimming_crab    640x480  blue_swimming_crab     566.89\n",
      "1   bsc (1).jpg  blue_swimming_crab   1280x720  blue_swimming_crab     540.60\n",
      "2   bsc (1).jpg  blue_swimming_crab  1920x1080  blue_swimming_crab     668.80\n",
      "3   bsc (2).jpg  blue_swimming_crab    640x480  blue_swimming_crab     537.00\n",
      "4   bsc (2).jpg  blue_swimming_crab   1280x720  blue_swimming_crab     493.99\n",
      "5   bsc (2).jpg  blue_swimming_crab  1920x1080  blue_swimming_crab     495.00\n",
      "6   bsc (3).jpg  blue_swimming_crab    640x480  blue_swimming_crab     484.99\n",
      "7   bsc (3).jpg  blue_swimming_crab   1280x720  blue_swimming_crab     449.99\n",
      "8   bsc (3).jpg  blue_swimming_crab  1920x1080  blue_swimming_crab     457.99\n",
      "9   bsc (4).jpg  blue_swimming_crab    640x480  blue_swimming_crab     453.00\n",
      "10  bsc (4).jpg  blue_swimming_crab   1280x720  blue_swimming_crab     450.00\n",
      "11  bsc (4).jpg  blue_swimming_crab  1920x1080  blue_swimming_crab     453.40\n",
      "12   mc (1).jpg            mud_crab    640x480            mud_crab     545.43\n",
      "13   mc (1).jpg            mud_crab   1280x720            mud_crab     476.96\n",
      "14   mc (1).jpg            mud_crab  1920x1080            mud_crab     459.44\n",
      "15   mc (2).jpg            mud_crab    640x480            mud_crab     463.00\n",
      "16   mc (2).jpg            mud_crab   1280x720            mud_crab     450.00\n",
      "17   mc (2).jpg            mud_crab  1920x1080            mud_crab     451.00\n",
      "18   mc (3).jpg            mud_crab    640x480            mud_crab     507.00\n",
      "19   mc (3).jpg            mud_crab   1280x720            mud_crab     460.99\n",
      "20   mc (3).jpg            mud_crab  1920x1080            mud_crab     458.00\n",
      "21   mc (4).jpg            mud_crab    640x480            mud_crab     454.00\n",
      "22   mc (4).jpg            mud_crab   1280x720            mud_crab     457.00\n",
      "23   mc (4).jpg            mud_crab  1920x1080            mud_crab     461.00\n",
      "24   tp (1).jpg         tiger_prawn    640x480         tiger_prawn     455.00\n",
      "25   tp (1).jpg         tiger_prawn   1280x720         tiger_prawn     454.00\n",
      "26   tp (1).jpg         tiger_prawn  1920x1080         tiger_prawn     458.01\n",
      "27   tp (2).jpg         tiger_prawn    640x480         tiger_prawn     449.31\n",
      "28   tp (2).jpg         tiger_prawn   1280x720         tiger_prawn     455.81\n",
      "29   tp (2).jpg         tiger_prawn  1920x1080         tiger_prawn     453.53\n",
      "30   tp (3).jpg         tiger_prawn    640x480         tiger_prawn     454.76\n",
      "31   tp (3).jpg         tiger_prawn   1280x720         tiger_prawn     453.68\n",
      "32   tp (3).jpg         tiger_prawn  1920x1080         tiger_prawn     453.00\n",
      "33   tp (4).jpg         tiger_prawn    640x480         tiger_prawn     454.00\n",
      "34   tp (4).jpg         tiger_prawn   1280x720         tiger_prawn     512.99\n",
      "35   tp (4).jpg         tiger_prawn  1920x1080         tiger_prawn     493.40\n",
      "36   ws (1).jpg     whiteleg_shrimp    640x480     whiteleg_shrimp     483.03\n",
      "37   ws (1).jpg     whiteleg_shrimp   1280x720     whiteleg_shrimp     495.89\n",
      "38   ws (1).jpg     whiteleg_shrimp  1920x1080     whiteleg_shrimp     481.60\n",
      "39   ws (2).jpg     whiteleg_shrimp    640x480     whiteleg_shrimp     498.74\n",
      "40   ws (2).jpg     whiteleg_shrimp   1280x720     whiteleg_shrimp     494.30\n",
      "41   ws (2).jpg     whiteleg_shrimp  1920x1080     whiteleg_shrimp     514.00\n",
      "42   ws (3).jpg     whiteleg_shrimp    640x480     whiteleg_shrimp     486.58\n",
      "43   ws (3).jpg     whiteleg_shrimp   1280x720     whiteleg_shrimp     501.99\n",
      "44   ws (3).jpg     whiteleg_shrimp  1920x1080     whiteleg_shrimp     512.00\n",
      "45   ws (4).jpg     whiteleg_shrimp    640x480     whiteleg_shrimp     508.00\n",
      "46   ws (4).jpg     whiteleg_shrimp   1280x720     whiteleg_shrimp     502.98\n",
      "47   ws (4).jpg     whiteleg_shrimp  1920x1080     whiteleg_shrimp     504.97\n",
      "48   rc (1).jpg          river_crab    640x480          river_crab     500.93\n",
      "49   rc (1).jpg          river_crab   1280x720          river_crab     503.49\n",
      "50   rc (1).jpg          river_crab  1920x1080          river_crab     502.57\n",
      "51   rc (2).jpg          river_crab    640x480          river_crab     516.35\n",
      "52   rc (2).jpg          river_crab   1280x720          river_crab     501.00\n",
      "53   rc (2).jpg          river_crab  1920x1080          river_crab     513.00\n",
      "54   rc (3).jpg          river_crab    640x480          river_crab     532.00\n",
      "55   rc (3).jpg          river_crab   1280x720          river_crab     499.99\n",
      "56   rc (3).jpg          river_crab  1920x1080          river_crab     484.99\n",
      "57   rc (4).jpg          river_crab    640x480          river_crab     494.00\n",
      "58   rc (4).jpg          river_crab   1280x720          river_crab     500.99\n",
      "59   rc (4).jpg          river_crab  1920x1080          river_crab     493.99\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa4712b-05b1-44ea-b12c-2e7aa914c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "blue_swimming_crab       1.00      1.00      1.00         4\n",
      "          mud_crab       1.00      1.00      1.00         4\n",
      "       tiger_prawn       1.00      1.00      1.00         4\n",
      "   whiteleg_shrimp       1.00      1.00      1.00         4\n",
      "        river_crab       1.00      1.00      1.00         4\n",
      "\n",
      "          accuracy                           1.00        20\n",
      "         macro avg       1.00      1.00      1.00        20\n",
      "      weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [0 0 4 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation ---\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=crustacean_system.class_names))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (TensorFlow)",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
